{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux\n",
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux/test\n",
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux\n",
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux/train\n",
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux\n",
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux\n"
     ]
    }
   ],
   "source": [
    "# %cd /home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux \n",
    "# %cd test\n",
    "# !rm -rf *.jpg\n",
    "# !rmdir unknown\n",
    "\n",
    "\n",
    "# %cd /home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux \n",
    "# %cd train\n",
    "# !rm -rf *.jpg\n",
    "# !rm -rf sample\n",
    "\n",
    "# %cd /home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux \n",
    "# !rm -rf valid\n",
    "# !rm -rf results\n",
    "# !rm -rf sample/train/\n",
    "# !rm -rf sample/valid/\n",
    "\n",
    "# %cd /home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux \n",
    "# !rmdir test\n",
    "# !rmdir train\n",
    "\n",
    "\n",
    "# !unzip -q test.zip\n",
    "# !unzip -q train.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'/home/ubuntu/courses/deeplearning1/nbs/lesson1'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /home/ubuntu/courses/deeplearning1/nbs/lesson1\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "current_dir = os.getcwd()\n",
    "LESSON_HOME_DIR = current_dir\n",
    "DATA_HOME_DIR = current_dir + '/data/redux'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "\n",
    "from utils import *\n",
    "from vgg16 import Vgg16\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action Plan\n",
    "1. Create Validation and Sample sets\n",
    "2. Rearrange image files into their respective directories\n",
    "3. Finetune and Train model\n",
    "4. Generate predictions\n",
    "5. Validation predictions\n",
    "6. Submit predictions to Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create validation set and sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "%mkdir valid\n",
    "%mkdir results\n",
    "%mkdir -p sample/train\n",
    "%mkdir -p sample/test\n",
    "%mkdir -p sample/valid\n",
    "%mkdir -p sample/results\n",
    "%mkdir -p test/unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m.\u001b[00m\r\n",
      "├── \u001b[01;34mresults\u001b[00m\r\n",
      "├── \u001b[01;34msample\u001b[00m\r\n",
      "│   ├── \u001b[01;34mresults\u001b[00m\r\n",
      "│   ├── \u001b[01;34mtest\u001b[00m\r\n",
      "│   ├── \u001b[01;34mtrain\u001b[00m\r\n",
      "│   └── \u001b[01;34mvalid\u001b[00m\r\n",
      "├── \u001b[01;34mtest\u001b[00m\r\n",
      "│   └── \u001b[01;34munknown\u001b[00m\r\n",
      "├── \u001b[01;34mtrain\u001b[00m\r\n",
      "└── \u001b[01;34mvalid\u001b[00m\r\n",
      "\r\n",
      "10 directories\r\n"
     ]
    }
   ],
   "source": [
    "!tree -d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux/train\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(2000) : os.rename(shuf[i], DATA_HOME_DIR + '/valid/' + shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Valid----\n",
      "\u001b[0m\u001b[01;35mcat.10004.jpg\u001b[0m\n",
      "\u001b[01;35mcat.10035.jpg\u001b[0m\n",
      "\u001b[01;35mcat.10036.jpg\u001b[0m\n",
      "\u001b[01;35mcat.1003.jpg\u001b[0m\n",
      "\u001b[01;35mcat.10045.jpg\u001b[0m\n",
      "ls: write error\n",
      "dog.9910.jpg\n",
      "dog.9920.jpg\n",
      "dog.997.jpg\n",
      "dog.9980.jpg\n",
      "dog.9999.jpg\n",
      "2000\n",
      "23000\n"
     ]
    }
   ],
   "source": [
    "!echo ----Valid----\n",
    "%ls ../valid | head -5 && ls ../valid  | tail -5 && ls ../valid  | wc -l\n",
    "%ls | wc -l\n",
    "# 2000 random files moved from /train to /valid\n",
    "# /valid has 2000 files\n",
    "# Now /train has 25000 - 2000 = 23000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(200) : copyfile(shuf[i], DATA_HOME_DIR + '/sample/train/' + shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;35mcat.10003.jpg\u001b[0m\n",
      "\u001b[01;35mcat.10037.jpg\u001b[0m\n",
      "\u001b[01;35mcat.10151.jpg\u001b[0m\n",
      "\u001b[01;35mcat.10262.jpg\u001b[0m\n",
      "\u001b[01;35mcat.10580.jpg\u001b[0m\n",
      "dog.9645.jpg\n",
      "dog.9697.jpg\n",
      "dog.9700.jpg\n",
      "dog.9884.jpg\n",
      "dog.996.jpg\n",
      "200\n",
      "23000\n"
     ]
    }
   ],
   "source": [
    "# Copied 200 files from /train to /sample/train\n",
    "%ls ../sample/train/ | head -5 && ls ../sample/train/ | tail -5 && ls ../sample/train/| wc -l\n",
    "%ls | wc -l\n",
    "# /sample/train has 200 files\n",
    "# /train has 23000 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux/valid\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(50) : copyfile(shuf[i], DATA_HOME_DIR + '/sample/valid/' + shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# Copied 50 random files from /valid to /sample/valid\n",
    "# /valid still has 2000 files, /sample/valid has 50\n",
    "%ls | wc -l\n",
    "%ls ../sample/valid/ | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rearrange files into their respective directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux/sample/train\n"
     ]
    }
   ],
   "source": [
    "#Divide cat/dog images into separate directories\n",
    "\n",
    "%cd $DATA_HOME_DIR/sample/train\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg cats/\n",
    "%mv dog.*.jpg dogs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux/sample/valid\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR/sample/valid\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg cats/\n",
    "%mv dog.*.jpg dogs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux/valid\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR/valid\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg cats/\n",
    "%mv dog.*.jpg dogs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux/train\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR/train\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg cats/\n",
    "%mv dog.*.jpg dogs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux/test\n"
     ]
    }
   ],
   "source": [
    "#Create single unknown class for test set\n",
    "%cd $DATA_HOME_DIR/test\n",
    "%mv *.jpg unknown/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "\n",
    "#Set path to sample/ path if desired\n",
    "path = DATA_HOME_DIR + '/' #'/sample/'\n",
    "test_path = DATA_HOME_DIR + '/test/' #We use all the test data\n",
    "results_path = DATA_HOME_DIR + '/results/'\n",
    "train_path = path + '/train/'\n",
    "valid_path = path + '/valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#You can experiment with no_of_epochs to improve the model\n",
    "batch_size = 64\n",
    "no_of_epochs=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Finetune the model\n",
    "batches = vgg.get_batches(train_path, batch_size=batch_size)\n",
    "val_batches = vgg.get_batches(valid_path, batch_size=batch_size * 2)\n",
    "vgg.finetune(batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch 0\n",
      "Epoch 1/1\n",
      "  512/23000 [..............................] - ETA: 8717s - loss: 1.0537 - acc: 0.6914"
     ]
    }
   ],
   "source": [
    "#Notice we are passing in the validation dataset to the fit() method\n",
    "#For each epoch we test our model against the validation set\n",
    "latest_weights_filename = None\n",
    "for epoch in range(no_of_epochs):\n",
    "    print \"Running epoch %d\" % epoch\n",
    "    vgg.fit(batches, val_batches, nb_epoch=1)\n",
    "    latest_weights_filename = 'ft%d.h5' % epoch\n",
    "    vgg.model.save_weights(results_path + latest_weights_filename)\n",
    "print \"Completed %s fit operations\" % no_of_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
