{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux\n",
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux/test\n",
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux\n",
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux/train\n",
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux\n",
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux\n",
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux\n"
     ]
    }
   ],
   "source": [
    "%cd /home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux \n",
    "%cd test\n",
    "!rm -rf *.jpg\n",
    "!rm -rf unknown\n",
    "!rm -rf sample\n",
    "\n",
    "\n",
    "%cd /home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux \n",
    "%cd train\n",
    "!rm -rf cats\n",
    "!rm -rf dogs\n",
    "!rm -rf *.jpg\n",
    "\n",
    "\n",
    "%cd /home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux \n",
    "!rm -rf valid\n",
    "!rm -rf results\n",
    "!rm -rf sample/train/\n",
    "!rm -rf sample/valid/\n",
    "!rm -rf sample/\n",
    "\n",
    "%cd /home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux \n",
    "!rmdir test\n",
    "!rmdir train\n",
    "\n",
    "%cd /home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux\n",
    "!unzip -q test.zip\n",
    "!unzip -q train.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'/home/ubuntu/courses/deeplearning1/nbs/lesson1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /home/ubuntu/courses/deeplearning1/nbs/lesson1\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "current_dir = os.getcwd()\n",
    "LESSON_HOME_DIR = current_dir\n",
    "DATA_HOME_DIR = current_dir + '/data/redux'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "\n",
    "from utils import *\n",
    "from vgg16 import Vgg16\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action Plan\n",
    "1. Create Validation and Sample sets\n",
    "2. Rearrange image files into their respective directories\n",
    "3. Finetune and Train model\n",
    "4. Generate predictions\n",
    "5. Validation predictions\n",
    "6. Submit predictions to Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create validation set and sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux\n",
      "\u001b[01;34m.\u001b[00m\n",
      "├── \u001b[01;34mresults\u001b[00m\n",
      "├── \u001b[01;34mtest\u001b[00m\n",
      "├── \u001b[01;34mtrain\u001b[00m\n",
      "└── \u001b[01;34mvalid\u001b[00m\n",
      "\n",
      "4 directories\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "%mkdir valid\n",
    "%mkdir results\n",
    "!tree -d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "./train\r\n",
      "./test\r\n",
      "./results\r\n",
      "./valid\r\n"
     ]
    }
   ],
   "source": [
    "#Store the folder structure in txt file\n",
    "!find . -type d > dirs.txt\n",
    "%cat dirs.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux/sample\n",
      ".\r\n",
      "./train\r\n",
      "./test\r\n",
      "./results\r\n",
      "./valid\r\n"
     ]
    }
   ],
   "source": [
    "!rm -rf sample\n",
    "#create sample folder\n",
    "%mkdir sample\n",
    "%cd sample\n",
    "! cat ../dirs.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create the same folder structure inside /sample\n",
    "!xargs mkdir -p < ../dirs.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux\n",
      "\u001b[01;34m.\u001b[00m\r\n",
      "├── \u001b[01;34mresults\u001b[00m\r\n",
      "├── \u001b[01;34msample\u001b[00m\r\n",
      "│   ├── \u001b[01;34mresults\u001b[00m\r\n",
      "│   ├── \u001b[01;34mtest\u001b[00m\r\n",
      "│   ├── \u001b[01;34mtrain\u001b[00m\r\n",
      "│   └── \u001b[01;34mvalid\u001b[00m\r\n",
      "├── \u001b[01;34mtest\u001b[00m\r\n",
      "├── \u001b[01;34mtrain\u001b[00m\r\n",
      "└── \u001b[01;34mvalid\u001b[00m\r\n",
      "\r\n",
      "9 directories\r\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "!tree -d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getFileNameFromPath(path):\n",
    "    return os.path.basename(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Move 2000 random jpg files from /train to /valid\n",
    "g = glob('train/*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(2000) : os.rename(shuf[i], DATA_HOME_DIR + '/valid/' + getFileNameFromPath(shuf[i]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Valid----\n",
      "\u001b[0m\u001b[01;35mcat.10011.jpg\u001b[0m\n",
      "\u001b[01;35mcat.10019.jpg\u001b[0m\n",
      "\u001b[01;35mcat.10035.jpg\u001b[0m\n",
      "\u001b[01;35mcat.10052.jpg\u001b[0m\n",
      "\u001b[01;35mcat.10053.jpg\u001b[0m\n",
      "ls: write error\n",
      "dog.9943.jpg\n",
      "dog.9962.jpg\n",
      "dog.9976.jpg\n",
      "dog.9981.jpg\n",
      "dog.9982.jpg\n",
      "2000\n",
      "23000\n"
     ]
    }
   ],
   "source": [
    "!echo ----Valid----\n",
    "%ls valid | head -5 && ls valid  | tail -5 && ls valid  | wc -l\n",
    "%ls train | wc -l\n",
    "# 2000 random files moved from /train to /valid\n",
    "# /valid has 2000 files\n",
    "# Now /train has 25000 - 2000 = 23000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Copy 200 random jpg files from /train to /sample/train\n",
    "g = glob('train/*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(200) : copyfile(shuf[i], DATA_HOME_DIR + '/sample/train/' + getFileNameFromPath(shuf[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;35mcat.10135.jpg\u001b[0m\n",
      "\u001b[01;35mcat.10145.jpg\u001b[0m\n",
      "\u001b[01;35mcat.10193.jpg\u001b[0m\n",
      "\u001b[01;35mcat.10286.jpg\u001b[0m\n",
      "\u001b[01;35mcat.10496.jpg\u001b[0m\n",
      "dog.9341.jpg\n",
      "dog.9365.jpg\n",
      "dog.9516.jpg\n",
      "dog.9575.jpg\n",
      "dog.9784.jpg\n",
      "200\n",
      "23000\n"
     ]
    }
   ],
   "source": [
    "# Copied 200 files from /train to /sample/train\n",
    "%ls sample/train/ | head -5 && ls sample/train/ | tail -5 && ls sample/train/| wc -l\n",
    "%ls train| wc -l\n",
    "# /sample/train has 200 files\n",
    "# /train has 23000 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd $DATA_HOME_DIR/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = glob('valid/*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(50) : copyfile(shuf[i], DATA_HOME_DIR + '/sample/valid/' + getFileNameFromPath(shuf[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# Copied 50 random files from /valid to /sample/valid\n",
    "# /valid still has 2000 files, /sample/valid has 50\n",
    "%ls valid | wc -l\n",
    "%ls sample/valid/ | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rearrange files into their respective directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux/sample/train\n"
     ]
    }
   ],
   "source": [
    "#Divide cat/dog images into separate directories\n",
    "\n",
    "%cd $DATA_HOME_DIR/sample/train\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg cats/\n",
    "%mv dog.*.jpg dogs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "%ls cats | wc -l\n",
    "%ls dogs | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux/sample/valid\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR/sample/valid\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg cats/\n",
    "%mv dog.*.jpg dogs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "%ls cats | wc -l\n",
    "%ls dogs | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux/valid\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR/valid\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg cats/\n",
    "%mv dog.*.jpg dogs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "%ls cats | wc -l\n",
    "%ls dogs | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux/train\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR/train\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg cats/\n",
    "%mv dog.*.jpg dogs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11500\n",
      "11500\n"
     ]
    }
   ],
   "source": [
    "%ls cats | wc -l\n",
    "%ls dogs | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux/test\n"
     ]
    }
   ],
   "source": [
    "#Create single unknown class for test set\n",
    "%mkdir -p $DATA_HOME_DIR/test/unknown\n",
    "%cd $DATA_HOME_DIR/test\n",
    "%mv *.jpg unknown/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n",
      "\u001b[0m\u001b[01;35m10000.jpg\u001b[0m\n",
      "\u001b[01;35m10001.jpg\u001b[0m\n",
      "\u001b[01;35m10002.jpg\u001b[0m\n",
      "\u001b[01;35m10003.jpg\u001b[0m\n",
      "\u001b[01;35m10004.jpg\u001b[0m\n",
      "\u001b[01;35m10005.jpg\u001b[0m\n",
      "\u001b[01;35m10006.jpg\u001b[0m\n",
      "\u001b[01;35m10007.jpg\u001b[0m\n",
      "\u001b[01;35m10008.jpg\u001b[0m\n",
      "\u001b[01;35m10009.jpg\u001b[0m\n",
      "ls: write error\n"
     ]
    }
   ],
   "source": [
    "%ls $DATA_HOME_DIR/test/unknown | wc -l\n",
    "%ls $DATA_HOME_DIR/test/unknown | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux/test'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "\n",
    "#Set path to sample/ path if desired\n",
    "path = DATA_HOME_DIR + '/sample'\n",
    "test_path = DATA_HOME_DIR + '/test/' #We use all the test data\n",
    "results_path = DATA_HOME_DIR + '/results/'\n",
    "train_path = path + '/train/'\n",
    "valid_path = path + '/valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux/sample\n",
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux/test/\n",
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux/results/\n",
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux/sample/train/\n",
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/redux/sample/valid\n"
     ]
    }
   ],
   "source": [
    "print path\n",
    "print test_path\n",
    "print results_path\n",
    "print train_path\n",
    "print valid_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#You can experiment with no_of_epochs to improve the model\n",
    "batch_size = 64\n",
    "no_of_epochs=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 2 classes.\n",
      "Found 50 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Finetune the model\n",
    "batches = vgg.get_batches(train_path, batch_size=batch_size)\n",
    "# val_batches is twice the number of batches because it doesn't need backprop, so needs less memory.\n",
    "val_batches = vgg.get_batches(valid_path, batch_size=batch_size * 2)\n",
    "vgg.finetune(batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch 0\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 94s - loss: 1.0912 - acc: 0.6250 - val_loss: 0.1669 - val_acc: 0.9200\n",
      "Completed 1 fit operations\n"
     ]
    }
   ],
   "source": [
    "#Notice we are passing in the validation dataset to the fit() method\n",
    "#For each epoch we test our model against the validation set\n",
    "latest_weights_filename = None\n",
    "for epoch in range(no_of_epochs):\n",
    "    print \"Running epoch %d\" % epoch\n",
    "    vgg.fit(batches, val_batches, nb_epoch=1)\n",
    "    latest_weights_filename = 'ft%d.h5' % epoch\n",
    "    vgg.model.save_weights(results_path + latest_weights_filename)\n",
    "print \"Completed %s fit operations\" % no_of_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Generate Predictions\n",
    "### Let's use our new model to make predictions on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "batches, preds = vgg.test(test_path, batch_size = batch_size * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For every image, vgg.test() generates two probabilities\n",
    "# based on how we've ordered the cats/dogs directories.\n",
    "# It looks like column one is cats and column 2 is dogs\n",
    "print preds[:5]\n",
    "\n",
    "filenames = batches.filenames\n",
    "print filenames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#You can verify the column ordering by viewing some images\n",
    "from PIL import Image\n",
    "Image.open(test_path + filenames[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save our test results arrays so we can use them again later\n",
    "save_array(results_path + 'test_preds.dat', preds)\n",
    "save_array(results_path + 'filenames.dat', filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_path + 'test_preds.dat'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate predictions\n",
    "Keras' fit() function conveniently shows us the value of the loss function, and the accuracy, after every epoch (\"epoch\" refers to one full run through all training examples). The most important metrics for us to look at are for the validation set, since we want to check for over-fitting.\n",
    "\n",
    "* Tip: with our first model we should try to overfit before we start worrying about how to reduce over-fitting - there's no point even thinking about regularization, data augmentation, etc if you're still under-fitting! (We'll be looking at these techniques shortly).\n",
    "\n",
    "As well as looking at the overall metrics, it's also a good idea to look at examples of each of:\n",
    "\n",
    "1. A few correct labels at random\n",
    "2. A few incorrect labels at random\n",
    "3. The most correct labels of each class (ie those with highest probability that are correct)\n",
    "4. The most incorrect labels of each class (ie those with highest probability that are incorrect)\n",
    "5. The most uncertain labels (ie those with probability closest to 0.5).\n",
    "\n",
    "Let's see what we can learn from these examples. (In general, this is a particularly useful technique for debugging problems in the model. However, since this model is so simple, there may not be too much to learn at this stage.)\n",
    "\n",
    "Calculate predictions on validation set, so we can find correct and incorrect examples:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#latest_weights_filename = \"ft2.h5\"\n",
    "vgg.model.load_weights(results_path+latest_weights_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_batches, probs = vgg.test(valid_path, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_batches.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = val_batches.filenames\n",
    "expected_labels = val_batches.classes #0 or 1\n",
    "\n",
    "#Round our predictions to 0/1 to generate labels\n",
    "our_predictions = probs[:,0]\n",
    "our_labels = np.round(1-our_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "#Helper function to plot images by index in the validation set \n",
    "#Plots is a helper function in utils.py\n",
    "def plots_idx(idx, titles=None):\n",
    "    plots([image.load_img(valid_path + '/' + filenames[i]) for i in idx], titles=titles)\n",
    "    \n",
    "#Number of images to view for each visualization task\n",
    "n_view = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#1. A few correct labels at random\n",
    "correct = np.where(our_labels==expected_labels)[0]\n",
    "print \"Found %d correct labels\" % len(correct)\n",
    "idx = permutation(correct)[:n_view]\n",
    "plots_idx(idx, our_predictions[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#2. A few incorrect labels at random\n",
    "incorrect = np.where(our_labels!=expected_labels)[0]\n",
    "print \"Found %d incorrect labels\" % len(incorrect)\n",
    "idx = permutation(incorrect)[:n_view]\n",
    "plots_idx(idx, our_predictions[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#3a. The images we most confident were cats, and are actually cats\n",
    "correct_cats = np.where((our_labels==0) & (our_labels==expected_labels))[0]\n",
    "print \"Found %d confident correct cats labels\" % len(correct_cats)\n",
    "most_correct_cats = np.argsort(our_predictions[correct_cats])[::-1][:n_view]\n",
    "plots_idx(correct_cats[most_correct_cats], our_predictions[correct_cats][most_correct_cats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#3b. The images we most confident were dogs, and are actually dogs\n",
    "correct_dogs = np.where((our_labels==1) & (our_labels==expected_labels))[0]\n",
    "print \"Found %d confident correct dogs labels\" % len(correct_dogs)\n",
    "most_correct_dogs = np.argsort(our_predictions[correct_dogs])[:n_view]\n",
    "plots_idx(correct_dogs[most_correct_dogs], our_predictions[correct_dogs][most_correct_dogs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#4a. The images we were most confident were cats, but are actually dogs\n",
    "incorrect_cats = np.where((our_labels==0) & (our_labels!=expected_labels))[0]\n",
    "print \"Found %d incorrect cats\" % len(incorrect_cats)\n",
    "if len(incorrect_cats):\n",
    "    most_incorrect_cats = np.argsort(our_predictions[incorrect_cats])[::-1][:n_view]\n",
    "    plots_idx(incorrect_cats[most_incorrect_cats], our_predictions[incorrect_cats][most_incorrect_cats])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#4b. The images we were most confident were dogs, but are actually cats\n",
    "incorrect_dogs = np.where((our_labels==1) & (our_labels!=expected_labels))[0]\n",
    "print \"Found %d incorrect dogs\" % len(incorrect_dogs)\n",
    "if len(incorrect_dogs):\n",
    "    most_incorrect_dogs = np.argsort(our_predictions[incorrect_dogs])[:n_view]\n",
    "    plots_idx(incorrect_dogs[most_incorrect_dogs], our_predictions[incorrect_dogs][most_incorrect_dogs])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#5. The most uncertain labels (ie those with probability closest to 0.5).\n",
    "most_uncertain = np.argsort(np.abs(our_predictions-0.5))\n",
    "plots_idx(most_uncertain[:n_view], our_predictions[most_uncertain])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps the most common way to analyze the result of a classification model is to use a confusion matrix. Scikit-learn has a convenient function we can use for this purpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(expected_labels, our_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can just print out the confusion matrix, or we can show a graphical view (which is mainly useful for dependents with a larger number of categories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, val_batches.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit predictions to Kaggle\n",
    "\n",
    "\n",
    "Here's the format Kaggle requires for new submissions:\n",
    "\n",
    "imageId,isDog\n",
    "1242, .3984\n",
    "3947, .1000\n",
    "4539, .9082\n",
    "2345, .0000\n",
    "\n",
    "Kaggle wants the imageId followed by the probability of the image being a dog. Kaggle uses a metric called Log Loss to evaluate your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load our test predictions from file\n",
    "preds = load_array(results_path + 'test_preds.dat')\n",
    "filenames = load_array(results_path + 'filenames.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Grab the dog prediction column\n",
    "isdog = preds[:,1]\n",
    "print \"Raw Predictions: \" + str(isdog[:5])\n",
    "print \"Mid Predictions: \" + str(isdog[(isdog < .6) & (isdog > .4)])\n",
    "print \"Edge Predictions: \" + str(isdog[(isdog == 1) | (isdog == 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
